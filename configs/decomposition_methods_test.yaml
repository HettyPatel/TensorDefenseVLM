# Comprehensive test of different tensor decomposition methods
seed: 42
results_dir: "results"
batch_size: 32
num_workers: 4

model:
  name: "clip"
  variant: "vit-base-patch32"

dataset:
  name: "nlphuji/flickr30k"
  split: "test"
  max_samples: 1000  # Using smaller sample size for testing
  trust_remote_code: true

attack:
  epsilon: 0.0313725 # 8/255
  steps: 10
  step_size: 0.0235294 # 6/255

defenses:
  # CP Decomposition Tests
  - name: "CP Final Norm (rank=16, alpha=0.1)"
    method: "cp"
    rank: 16
    alpha: 0.1
    target_layer: "final_norm"
    vision_layer_idx: -1

  - name: "CP Final Norm (rank=32, alpha=0.2)"
    method: "cp"
    rank: 32
    alpha: 0.2
    target_layer: "final_norm"
    vision_layer_idx: -1

  - name: "CP Final Norm (rank=64, alpha=0.5)"
    method: "cp"
    rank: 64
    alpha: 0.5
    target_layer: "final_norm"
    vision_layer_idx: -1

  - name: "CP Attention (rank=32, alpha=0.2)"
    method: "cp"
    rank: 32
    alpha: 0.2
    target_layer: "attention"
    vision_layer_idx: -1

  - name: "CP MLP (rank=32, alpha=0.2)"
    method: "cp"
    rank: 32
    alpha: 0.2
    target_layer: "mlp"
    vision_layer_idx: -1

  # Tucker Decomposition Tests
  - name: "Tucker Final Norm (rank=16, alpha=0.1)"
    method: "tucker"
    rank: 16
    alpha: 0.1
    target_layer: "final_norm"
    vision_layer_idx: -1

  - name: "Tucker Final Norm (rank=32, alpha=0.2)"
    method: "tucker"
    rank: 32
    alpha: 0.2
    target_layer: "final_norm"
    vision_layer_idx: -1

  - name: "Tucker Final Norm (rank=64, alpha=0.5)"
    method: "tucker"
    rank: 64
    alpha: 0.5
    target_layer: "final_norm"
    vision_layer_idx: -1

  - name: "Tucker Attention (rank=32, alpha=0.2)"
    method: "tucker"
    rank: 32
    alpha: 0.2
    target_layer: "attention"
    vision_layer_idx: -1

  - name: "Tucker MLP (rank=32, alpha=0.2)"
    method: "tucker"
    rank: 32
    alpha: 0.2
    target_layer: "mlp"
    vision_layer_idx: -1

  # Tensor Train Decomposition Tests
  - name: "TT Final Norm (rank=16, alpha=0.1)"
    method: "tt"
    rank: 16
    alpha: 0.1
    target_layer: "final_norm"
    vision_layer_idx: -1

  - name: "TT Final Norm (rank=32, alpha=0.2)"
    method: "tt"
    rank: 32
    alpha: 0.2
    target_layer: "final_norm"
    vision_layer_idx: -1

  - name: "TT Final Norm (rank=64, alpha=0.5)"
    method: "tt"
    rank: 64
    alpha: 0.5
    target_layer: "final_norm"
    vision_layer_idx: -1

  - name: "TT Attention (rank=32, alpha=0.2)"
    method: "tt"
    rank: 32
    alpha: 0.2
    target_layer: "attention"
    vision_layer_idx: -1

  - name: "TT MLP (rank=32, alpha=0.2)"
    method: "tt"
    rank: 32
    alpha: 0.2
    target_layer: "mlp"
    vision_layer_idx: -1 