# Full COCO experiment (3000 images)
seed: 42
results_dir: "results"
batch_size: 32
num_workers: 4

model:
  name: "clip"
  variant: "vit-base-patch32"

dataset:
  name: "shunk031/MSCOCO"
  year: 2014
  coco_task: "captions"
  split: "train"
  max_samples: 3000
  trust_remote_code: true

attack:
  epsilon: 0.0313725 # 8/255
  steps: 10
  step_size: 0.0235294 # 6/255

defenses:
  - name: "CP Final Norm (alpha=0.2)"
    method: "cp"
    rank: 32
    alpha: 0.2
    target_layer: "final_norm"
    vision_layer_idx: -1

  - name: "CP Attention (alpha=0.2)"
    method: "cp"
    rank: 32
    alpha: 0.2
    target_layer: "attention"
    vision_layer_idx: -1

  - name: "CP MLP (alpha=0.2)"
    method: "cp"
    rank: 32
    alpha: 0.2
    target_layer: "mlp"
    vision_layer_idx: -1

  - name: "Tucker Final Norm (alpha=0.2)"
    method: "tucker"
    rank: 32
    alpha: 0.2
    target_layer: "final_norm"
    vision_layer_idx: -1
    
  - name: "CP Multi-Layer (2 Layers)"
    layers:
      - method: "cp"
        rank: 32
        alpha: 0.2
        target_layer: "final_norm"
        vision_layer_idx: -1
      - method: "cp"
        rank: 32
        alpha: 0.2
        target_layer: "final_norm"
        vision_layer_idx: -2

  - name: "CP Multi-Layer (5 Layers)"
    layers:
      - method: "cp"
        rank: 32
        alpha: 0.2
        target_layer: "final_norm"
        vision_layer_idx: -1
      - method: "cp"
        rank: 32
        alpha: 0.2
        target_layer: "final_norm"
        vision_layer_idx: -2
      - method: "cp"
        rank: 32
        alpha: 0.2
        target_layer: "final_norm"
        vision_layer_idx: -3
      - method: "cp"
        rank: 32
        alpha: 0.2
        target_layer: "final_norm"
        vision_layer_idx: -4
      - method: "cp"
        rank: 32
        alpha: 0.2
        target_layer: "final_norm"
        vision_layer_idx: -5
